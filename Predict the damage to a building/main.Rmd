---
title: "Predict the damage to a building"
author: "Mohammed Ali"
date: "July 3, 2018"
output:
  html_document:
    toc: true
    fig_width: 16
    fig_height: 10
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(DataExplorer)
library(knitr)
library(kableExtra)
library(caTools)
library(rpart)
library(rpart.plot)
library(ROCR)
library(randomForest)
library(caret)
library(e1071)
```

# Train
First let us investigate training dataset, the main dataset.

```{r train_load_basic_structure}
train <- as_tibble(read.csv("data/train.csv"))
glimpse(train)
```
The logical feaures that start with *has* is of type double which will affect the later analysis badly, so let us convert them to a factor of 2 values (**0**, **1**)

```{r convert_logical_to_factors}
train[, 5:13] <- map_dfr(train[, 5:13], as.factor)
```

Let us investigate the data now 
```{r summary}
summary(train)
plot_str(train)
```

Ok, now we can perform our analysis on our dataset

## Data Profiling Report
### Basic Statistics
```{r Basic_Statistics}
stat <- introduce(train)
names(stat) <- c("Rows", "Columns", "Discrete columns", "Continuous columns", "All missing columns", "Missing observations", "Total observations", "Memory allocation")

gather(stat, Name, Value) %>%
  kable(format.args = list(decimal.mark = ".", big.mark = ",")) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

### Missing Data Profile
Though there are no many missing data, let us see how the missing rows are distributed.
```{r data_str}
plot_missing(train)
```


Strange engouh, all missing data in *has_reoair_started* feature which indicates that there is an issue in tracking these building reparing or they might be removed at all, let us see.

### Univariate Distribution
Let us see how the *univariate* is doing

#### Continuous Features
```{r uni_var}
plot_histogram(train)
```

and another view
```{r}
plot_density(train)
```
It is clear that there is more damged areas than others.

#### Discreate Features
```{r bar_chart}
plot_bar(train)
```

My Notes from above:

* I think we can exclude *has_repair_started* feaure, clearly it dose not contribute to the building damage degree.

* Other that *area_assessed* feature, features seems not to contribute too much to the target variable.

Let us see the correlation between them

#### Correlation Analysis
```{r cor_analysis}
plot_correlation(train)
```

From correlation analysis we found that:

* There is a strong positive correlaion between *Grade 1* damage and missing information in *has_repair_sarted* feature, and it seems like false correlation.

* *Grade 5* has strong positive correlation with *area_assessed_being_removed* and strong negative correlation with *area_assessed_both*

* Other correlations are so week.


let us include other complementary dataset and see the corrleations

## Feature Engieering
### Building Structure
Let us start by adding building structure features, first we read the dataset.
```{r building_structure}
structure <- as_tibble(read.csv("data/Building_Structure.csv"))
glimpse(structure)
```


We have 2 quick notes here:

* The number of observations is much more than the train dataset observations which mean it include observations of both train and test datasets. So, we either join the train and test dataset or split this dataset, I will select the first choice.

* We need to convert logical features into factors.

Let us combine train and test datasets
```{r train_test_join}
test <- as_tibble(read.csv("data/test.csv"))
test[, 4:12] <- map_dfr(test[, 4:12], as.factor)
buildings_all <- full_join(train, test)
```

It seems that there are 12 buildings in structure dataset have no records in the building datasets.
Now let us add structure features
```{r buildings_all_structures_join}
structure[, 18:28] <- map_dfr(structure[, 18:28], as.factor)
buildings_all <- full_join(buildings_all, structure)
```

### Building Ownership
Now let us add building ownership as well
```{r ownership}
ownership <- as_tibble(read.csv("data/Building_Ownership_Use.csv"))
glimpse(ownership)
```

Not let us combine it to the main dataset

```{r buildings_all_ownership_join}
ownership[, 5:17] <- map_dfr(ownership[, 5:17], as.factor)
buildings_all <- full_join(buildings_all, ownership)
#buildings_all[, c(16:18, 20:21)] <- map_dfr(buildings_all[, c(16:18, 20:21)], as.factor)
glimpse(buildings_all)
```

Now let us investigate the main dataset

### Basic Statistics
```{r all_sum}
summary(buildings_all)
```

### Full missing data profile

```{r all_missing}
plot_missing(buildings_all)
```
The missing information still in good rate, damage grade has 40% missing data because it belongs to the test data
### Full Continous Profile

```{r all_histogram}
plot_histogram(buildings_all)
```
There is defintely something wrong in the *pre* and *post* features

```{r all_density}
plot_density(buildings_all)
```


### Full Discreate Profile

```{r all_discreate}
plot_bar(buildings_all)
```

### Full Correlation Profile
`vdcmun_id`, `district_id` and `ward_id` has the identical effect we will use only one of them

```{r all_cor}
plot_correlation(buildings_all[,c("damage_grade", "height_ft_post_eq", "district_id", "count_floors_pre_eq", "age_building", "plinth_area_sq_ft", "height_ft_pre_eq","height_ft_post_eq" )])
```

```{r}
plot_correlation(buildings_all[, c(1:5)], type = "d")
plot_correlation(buildings_all[, c(3, 6:10)], type = "d")
plot_correlation(buildings_all[, c(3, 11:15)], type = "d")
plot_correlation(buildings_all[, c(3, 16:20)], type = "d")
plot_correlation(buildings_all[, c(3, 21:25)], type = "d")
plot_correlation(buildings_all[, c(3, 26:30)], type = "d")
plot_correlation(buildings_all[, c(3, 31:35)], type = "d")
plot_correlation(buildings_all[, c(3, 36:40)], type = "d")
plot_correlation(buildings_all[, c(3, 41:45)], type = "d")
plot_correlation(buildings_all[, c(3, 46:50)], type = "d")
plot_correlation(buildings_all[, c(3, 51:53)], type = "d")
```


# Model building

Splite data again to training and testing

```{r}
training_all <- buildings_all[!is.na(buildings_all$damage_grade),]
testing_all <- buildings_all[is.na(buildings_all$damage_grade),]
```

I will be using 10 fold Cross Validation. That is, 90% of the data is used to train the random forest model.

```{r}
inTrain <- createDataPa(y=full_training$SalePrice,p=0.9,list=FALSE)
```


