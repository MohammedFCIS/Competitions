---
title: "Damage Prediction Model"
author: "Mohammed Ali"
date: "August 4, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(useful)
library(h2o)
```

#Load Data

```{r}
buildings <- as_tibble(read.csv("buildings_final.csv"))
glimpse(buildings)
summary(buildings)
```


# Data Preperation

```{r}
buildings$X <- NULL #remove the index column
#buildings$damage_grade <- as.factor(buildings$damage_grade_id)
train <- subset(buildings, !is.na(buildings$buildings_all.damage_grade))
test <- subset(buildings, is.na(buildings$buildings_all.damage_grade))
summary(train)
```

# Feature Selection Approaches
Finding the most important predictor variables (of features) that explains major part of variance of the response variable is key to identify and build high performing models.

## Step-wise Regression method
```{r}
# base.mod <- lm(damage_grade ~ 1 , data= train)  # base intercept only model
# all.mod <- lm(damage_grade ~ . , data= train) # full model with all predictors
# stepMod <- step(base.mod, scope = list(lower = base.mod, upper = all.mod), direction = "both", trace = 0, steps = 1000)  # perform step-wise algorithm
# shortlistedVars <- names(unlist(stepMod[[1]])) # get the shortlisted variable.
# shortlistedVars <- shortlistedVars[!shortlistedVars %in% "(Intercept)"]  # remove intercept
# print(shortlistedVars)
# summary(stepMod)
```

# Model Building using H2O

## Preparation

```{r}
localH2O <- h2o.init(nthreads = -1)
h2o.init()
train.h2o <- as.h2o(train)
test.h2o <- as.h2o(test)
```
Using column index, we need to identify variables to be used in modeling as follows:

```{r}
colnames(train.h2o)
```

```{r}
#dependent variable (damage_grade)
y.dep <- 81

#independent variables (from selection step)
#x.indep <- c(2, 4:5, 16, 33:38, 51:56) #GMB score 0.65694 0.66451
#x.indep <- c(2:5, 14:16, 32:56) #GMB score 0.67583
#x.indep <- c(2:5, 8:16, 32:56) #GMB score 0.67801
#x.indep <- c(2:19, 32:56) #GMB score 0.68003
x.indep <- c(2:19, 32:79) #GMB score 0.69091
x.indep.all <- c(1, 80:81)
ntrees_opt <- c(1000)
maxdepth_opt <- c(12)
hyper_parameters <- list(ntrees=ntrees_opt,
                         max_depth=maxdepth_opt)
```


## Multiple Regression

```{r}
regression.model <- h2o.glm( y = y.dep, x = x.indep, training_frame = train.h2o, family = "multinomial")
h2o.performance(regression.model)
```

### Prediction
```{r}
predict.reg <- as.data.frame(h2o.predict(regression.model, test.h2o))
sub_reg <- data.frame(building_id = test$buildings_all.building_id, damage_grade = predict.reg$predict)
write.csv(sub_reg, file = "sub_reg.csv", quote = FALSE, row.names=FALSE)
```


## Random Forest
```{r}
#  system.time(
# rforest.model <- h2o.randomForest(y=y.dep, x=x.indep, training_frame = train.h2o, ntrees = 1000, mtries = 3, max_depth = 4, seed = 1122)
# )
# h2o.performance(rforest.model)
# h2o.varimp(rforest.model)

r <- h2o.runif(train.h2o)
trainHex.split <- h2o.splitFrame(train.h2o, ratios=.8)

grid <- h2o.grid("randomForest", hyper_params = hyper_parameters,
                 y = y.dep, x = x.indep,
                 seed = 123,
                 training_frame = trainHex.split[[1]],
                 validation_frame = trainHex.split[[2]])
# print out all prediction errors and run times of the models
grid

# print out the mse for all of the models
model_ids <- grid@model_ids
mse <- vector(mode="numeric", length=0)
grid_models <- lapply(model_ids, function(model_id) { model = h2o.getModel(model_id) })
for (i in 1:length(grid_models)) {
   print(sprintf("mse: %f", h2o.mse(grid_models[[i]])))
   mse[i] <- h2o.mse(grid_models[[i]])
}

best_id <- model_ids[order(mse,decreasing=F)][1]
best_id

fit.best <- h2o.getModel(model_id = best_id[[1]])
h2o.varimp(fit.best)
```

### Prediction
```{r}
system.time(predict.rforest <- as.data.frame(h2o.predict(fit.best, test.h2o)))
sub_rf <- data.frame(building_id = test$buildings_all.building_id, damage_grade = predict.rforest$predict)
write.csv(sub_rf, file = "sub_rf_best.csv", quote = FALSE, row.names=FALSE)
```

## GBM 

```{r}
# system.time(
# gbm.model <- h2o.gbm(y=y.dep, x=x.indep, training_frame = train.h2o, ntrees = 1100, max_depth = 6, learn_rate = 0.01, seed = 1122)
# )
# h2o.performance (gbm.model)
grid <- h2o.grid("gbm", hyper_params = hyper_parameters,
                 y = y.dep, x = x.indep,
                 distribution="AUTO",
                 training_frame = trainHex.split[[1]],
                 validation_frame = trainHex.split[[2]])
grid

# print out the mse for all of the models
model_ids <- grid@model_ids
mse <- vector(mode="numeric", length=0)
grid_models <- lapply(model_ids, function(model_id) { model = h2o.getModel(model_id) })
for (i in 1:length(grid_models)) {
   print(sprintf("mse: %f", h2o.mse(grid_models[[i]])))
   mse[i] <- h2o.mse(grid_models[[i]])
}


best_id <- model_ids[order(mse,decreasing=F)][1]
best_id

fit.best <- h2o.getModel(model_id = best_id[[1]])
h2o.varimp(fit.best)
RMPSE<- function(predicted, actual) {
  rmpse <- sqrt(mean((actual/predicted-1)^2))
  return(list(metric = "RMPSE", value = rmpse))
}
```

### Prediction
```{r}
predict.gbm <- as.data.frame(h2o.predict(fit.best, test.h2o))
            
sub_gbm <- data.frame(building_id = test$buildings_all.building_id, damage_grade = predict.gbm$predict)
write.csv(sub_gbm, file = "sub_gbm_3.csv", quote = FALSE, row.names=FALSE)
```

## Deep Learning

```{r}
system.time(
             dlearning.model <- h2o.deeplearning(y = y.dep,
             x = x.indep,
             training_frame = train.h2o,
             epoch = 60,
             hidden = c(150,150),
             activation = "Rectifier",
             seed = 1122
             )
)
```

###Prediction

```{r}
predict.dl <- as.data.frame(h2o.predict(dlearning.model, test.h2o))
sub_dl <- data.frame(building_id = test$buildings_all.building_id, damage_grade = predict.dl$predict)
write.csv(sub_dl, file = "sub_dl6.csv", quote = FALSE, row.names=FALSE)
```


## Random Forest (all)
```{r}
system.time(
gbm.model <- h2o.gbm(y=y.dep, x=x.indep.all, training_frame = train.h2o, ntrees = 1000, max_depth = 4, learn_rate = 0.01, seed = 1122)
)
h2o.performance (gbm.model)
h2o.varimp(gbm.model)
```