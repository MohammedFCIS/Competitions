---
title: "Startups Business Analytics"
author: "Mohammed Ali"
date: "February 17, 2018"
output:
    html_document:
      toc : true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
```

# Objective
Our main goal here is to see how we can walk through a business case to analysis it and conclude useful results from it. Although the dataset here is dummy one but it has the same issues for any real dataset, except the huge size, like:

* A lot of predictors to comperhend and get usefl info from them.
* Data has a lot of missing, unclear items.
* Amiguate relation between the predictors

So let us begin our journey.

# Data Wrangling
First we will read the data using `read_csv` methof from `readr` packing within `tidyverse` package.

```{r read_data, message=FALSE}
startups <- read_csv("data/CAX_Startup_Data.csv")
```
So we have `r nrow(startups)` observations belongs to `r ncol(startups)` variables, one of them is the response variable that we would to designate later for predction and the rest are the predictors.

Let us see how the first 5 rows of the data looks like
```{r data_head}
head(startups, 5)
```

From that it seems we have the following notes:

* There are many missong values 
* Missing values are not only marked as `NA` but there are other values like `No Info` or just an empty string.
* Varaible are read as _characters_ datatype by default and would need to be probably converted to their _original_ data type(dates, factors, numeric)
* There are variables clearly will need special processing like `Short Description of company profile` , `Specialization of highest education` or `
Investors`
* There are issues in texual columns (upper and lower case, different format, etc..)
* Clearly `Dependent-Company Status` is the response variable.

So, the following are the steps we will conduct to clean our dataset

* Unify the way missing data are marked.
* Will convert the variables into their proper datatypes.
* Remove column with missed data over 40%.

## Setup Missing Data
```{r set_missing}
set_missing <- function(x) {
  # Replace 'No Info' with NA
  x[x == 'No Info'] <- NA
  # Replace empty string with NA
  x[x == ''] <- NA
  return(x)
}

startups <- map_df(startups, set_missing)
```

## Variables Correct type
### Factor Variables

Construct factor of factor variables and convert them

```{r convert_factors}
factor_cols <- c(2, 12, 16:17, 24, 26:65, 67, 71, 73, 75:87, 89:91, 93, 97, 100:101)
startups[, factor_cols] <- map_df(startups[, factor_cols], toupper)
startups[, factor_cols] <- map_df(startups[, factor_cols], as.factor)
```

### Numeric Variables
Construct factor of numeric variables and convert them

```{r convert_numeric, message=FALSE, warning=FALSE}
numeric_cols <- c(3:5,10,11,18:23,25,61,66,68:70,72,74,88,92,94:96,98,99,102:116)
startups[, numeric_cols] <- map_df(startups[, numeric_cols], as.numeric)
```

### Date Variables
Construct factor of date variables and convert them

```{r convert_date}
date_cols <- c(13:14)
startups[, date_cols] <- map_df(startups[, date_cols], mdy)
```

## Remove polluted predictors
Now, as the variables in their proper data types, let us remove predictors with more than 40% missing data

```{r remove_poll_vars}
startups <- startups[colSums(is.na(startups))/nrow(startups) < .4]
dim(startups)
```
It seems we git rid off 3 variables, let us take another look at the data now
```{r top_5}
head(startups)
```

Much better.

# Exploratory Data Analysis

# Feature Engineering

# Pre-Modeling Processing
## Missing Values

## More Exploration

## Hypothesis Testing

## Predictor Selection
