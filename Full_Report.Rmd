---
title: "Mercari Price Suggestion Challenge"
author: "Ali Ezzat, Mohammed Ali"
date: "December 30, 2017"
output: 
  pdf_document:
    toc: yes
    toc_depth: 2
  html_document:
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr) #data frame manipulation
library(ggplot2) #visualization
library(data.table) #reading table
library(magrittr) #code enhancement
library(scales) #for plot scaling
library(stringr) #string operations
library(quanteda) #text mining
library(gridExtra) # for plotting many plots in grids

```

# About
Mercari’s [challenge](https://www.kaggle.com/c/mercari-price-suggestion-challenge) is to build an algorithm that automatically suggests the right product prices. You’ll be provided user-inputted text descriptions of their products, including details like product category name, brand name, and item condition.

# Exploratory Data Analysis
## Data overview
* Load training data
```{r loadData, message = FALSE, warning = FALSE, tidy = TRUE}
train <- fread("Mercari-Price-Suggestion-Challenge/data/train.tsv", sep = "\t", stringsAsFactors = FALSE, showProgress = FALSE)
```

* Inspect structure
```{r inspectStructure}
glimpse(train)
```
At the first glance, excluding the *train_id* column, the numeric data are only 3 columns one of them is the response variable _price_, while the other two are factor data which mean that we have a very limited number of features and that mean we will need the help of the other four text predictors to build our model. So let us investigate these features one by one to see what we can do.

## Price (The response/target variable)
Let’s start with an analysis of the response0 variable: price. First, the range of item prices:
```{r}
summary(train$price)
```
It seems there are items are givem as gifts (min. is 0), and we have a few very expensive items as well.
Let us visualize it for more clear picture
```{r}
ggplot(data = train, aes(x = price)) + 
    geom_histogram(fill = 'darkblue') +
    labs(title = 'Histogram of price')
```
It seems because we have a very expensive items (and very view) we will need to take the log for better analysis
```{r}
ggplot(data = train, aes(x = log(price))) + 
    geom_histogram(fill = 'darkblue') +
    labs(title = 'Histogram of log item price')
```
Now, it is much better and clear, but it seems taking log of prices made the free/gift items to be omitted, as taking log for 0 is undefined, so we will have to add a dummy 1 to include it with us in the plot, consider it a tax :P .
```{r}
ggplot(data = train, aes(x = log(price + 1))) + 
    geom_histogram(fill = 'darkblue') +
    labs(title = 'Histogram of log item price + 1') +
  geom_rug() 
     
```
So, finally we have the gift/free items in the plot and it seems like an outlier along with the pricy data, as we have a nearly normal distibution for the prices. Let us investigate the distribution more. 
It seems the data is centered between 3 and 7, as also the following statistics confirm.
```{r}
summary(log(train$price + 1))

```
## Item Condition
Item condition is a factor data, so let us convert it to a factor first.

```{r}
#item condition factor
train$item_condition_id <- as.factor(train$item_condition_id)
levels(train$item_condition_id)
```
Now, let us see the statistics summary of items conditions
```{r}
table(train$item_condition_id)
```

We can confirm it more by the following plot
```{r tidy=TRUE}
train[, .N, by = item_condition_id] %>%
    ggplot(aes(x = item_condition_id, y = N/1000)) +
    geom_bar(stat = 'identity', fill = 'cyan2') + 
    labs(x = 'Item condition', y = 'Number of items (000s)', title = 'Number of items by condition category')
```
It seems most of the items are in condition _1_ which is, I do not know there is no ordinal description in the compition. So we do not know if it _1_ is the best or the worst. However, hanks to kaggler @Juraj for pointing out that in fact condition 1 is the best and 5 is the worst. 

Now, let us compare the _item conditions_ predictor aginst the response variable _price_

```{r tidy=TRUE}
train[, .(.N, median_price = median(price)), by = item_condition_id][order(item_condition_id)]
ggplot(data = train, aes(x = item_condition_id, y = log(price + 1))) + 
    geom_boxplot(fill = 'cyan2', color = 'darkgrey')
```



It seems that item condition is not the main contributor to the price as the best price at condition _5_ with few items and the second best price at condition _1_ with a lot of items.

## Shipping
It is the second numeric facotr predictor. It is simply _1_ when shipping item is paied by the seller and _0_ otherwise.
Let us convert it to a facotr and see its statistics

```{r}
#shupping
train$shipping <- as.factor(train$shipping)
levels(train$shipping)
table(train$shipping)
```
It does not seem contributing that much to the reponse variable, so let us investigate its relation with the _price_

```{r}
train %>%
    ggplot(aes(x = log(price+1), fill = shipping)) + 
    geom_density(adjust = 2, alpha = 0.6) + 
    labs(x = 'Log price', y = '', title = 'log(price) vs. shipping')
```
It seems that if you are going to pay for the shipping you will have a little lower price, but not that much right !!
# Brand
Clearly the two numeric predictor factors are not contributing so much into the response variable.
How many brands we have?
```{r}
length(unique(train$brand_name))

```
Wow, that is a lot. So, let us try to investigate the text predictors and begin with the _brand_ predictor.

```{r}
train[, .(median_price = median(price)), by = brand_name] %>%
    head(25) %>%
    ggplot(aes(x = reorder(brand_name, median_price), y = median_price)) + 
    geom_point(color = 'cyan2') + 
    scale_y_continuous(labels = scales::dollar) + 
    coord_flip() +
    labs(x = '', y = 'Median price', title = 'Top 25 most expensive brands') 

```
OK, finally we have a strongly contributer predictor. It seems that brands affect prices as it should be.

## Item Categories
Now it is _item categories_ turn, we expect a lot from this variable. Let us begin by see how many categoris are there? 

```{r}
length(unique(train$category_name))
```

OK, there are a lot of categories here. So, how it looks like?

```{r}
sort(table(train$category_name), decreasing = TRUE)[1:10]
```
OK, there are a lot for women here :). 
It seems that we have a 3 level of category here, so let us investigate more. Now let us see how cateogries influnce _price_

```{r tidy=TRUE}
train[, .(median = median(price)), by = category_name][order(median, decreasing = TRUE)][1:30] %>%
    ggplot(aes(x = reorder(category_name, median), y = median)) + 
    geom_point(color = 'orangered2') + 
    coord_flip() + 
    labs(x = '', y = 'Median price', title = 'Median price by item category (Top 30)') + 
    scale_y_continuous(labels = scales::dollar)
```

As expected, categories are contributing so much into the response variable _price_ with _Vintage & Collectibles_ in the top followed by _kids toys_ !!
So let us split each category to its level to see how each level contributs in the _price_

```{r tidy=TRUE}
train[, c("level_1_cat", "level_2_cat",  "level_3_cat") := tstrsplit(train$category_name, split = "/")]
head(train[, c("level_1_cat", "level_2_cat", "level_3_cat")])
```
We can now convert them to factors for easier and better analysis
```{r}
train$level_1_cat <- as.factor(train$level_1_cat)
train$level_2_cat <- as.factor(train$level_2_cat)
train$level_3_cat <- as.factor(train$level_3_cat)
```

Now let us see the statistics of level1
```{r}
length(levels(train$level_1_cat))
table(train$level_1_cat)
```
, and level 2
```{r}
length(levels(train$level_2_cat))
table(train$level_2_cat)[1:10]
```

and the third level
```{r}
length(levels(train$level_3_cat))
table(train$level_3_cat)[1:10]
```

```{r}
```

# Model Building
# Conclusion
# Credit
[Troy Walters](https://www.kaggle.com/captcalculator)

# eBay acronyms
A-E
B&W: black and white

BC: back cover (usually used as a description for books)

BIN: Buy It Now

CIP: customer initiated payment

DOA: dead on arrival (an item that doesn't work or is broken when it's received)

DSR: detailed seller rating (additional Feedback ratings buyers can give sellers)

EST: Eastern Standard Time

EUC: excellent used condition

F-I
FAQ: frequently asked questions (a list of questions with answers.)

FB: Feedback

FC: fine condition

FOB: freight on board (usually means something has shipped)

FS: full screen (usually applied to a DVD or video format)

FVF: final value fee

G: good condition

GBP: Great Britain pounds

GU: gently used (item that has been used but shows little wear, accompanied by explanation of wear)

HP: home page

HTF: hard to find

HTML: hypertext markup language (the language used to create web pages)

IE: Internet Explorer

IM: instant messaging

INIT: initials

ISP: Internet service provider (a company that gives you access to the Internet)

J-M
JPG: JPEG (preferred file format for pictures on eBay, pronounced "jay-peg")

LTBX: letterbox (video format that recreates a widescreen image)

LTD: limited edition

MNT: mint or in perfect condition (a subjective term that doesn't necessarily mean new)

MIB: mint in box

MIJ: made in Japan

MIMB: mint in mint box

MIMP: mint in mint package

MIP: mint in package

MNB: mint no box

MOC: mint on card

MOMC: mint on mint card

MONMC: mint on near mint card

MWBT: mint with both tags

MWMT: mint with mint tags

N-P
NARU: not a registered user (also a suspended user)

NBW: never been worn

NC: no cover

NIB: new in box

NM: near mint

NOS: new old stock

NR: no reserve price (for an auction-style listing)

NRFB: never removed from box

NWT: new with tags

NWOB: new without box

NWOT: new without original tags

OEM: original equipment manufacturer

OOP: out of print

PST: Pacific Standard Time

Q-Z
RET: retired

SCR: scratch

S/O: sold out

Sig: signature


